{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3, ques 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.svmutil import * #importing LIBSVM to perform classification task using SVM\n",
    "from libsvm.svm import *\n",
    "import pandas as pd #importing pandas to read a file\n",
    "import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV files and storing them in Dataframe objects using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9980</td>\n",
       "      <td>-162.771692</td>\n",
       "      <td>935.535743</td>\n",
       "      <td>210.969540</td>\n",
       "      <td>-614.882063</td>\n",
       "      <td>301.029607</td>\n",
       "      <td>214.300365</td>\n",
       "      <td>-182.519084</td>\n",
       "      <td>179.170125</td>\n",
       "      <td>65.932431</td>\n",
       "      <td>-158.061641</td>\n",
       "      <td>...</td>\n",
       "      <td>102.574200</td>\n",
       "      <td>-59.288106</td>\n",
       "      <td>-45.326482</td>\n",
       "      <td>-173.349505</td>\n",
       "      <td>-31.392617</td>\n",
       "      <td>172.690845</td>\n",
       "      <td>-24.677229</td>\n",
       "      <td>-261.011283</td>\n",
       "      <td>110.302253</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9981</td>\n",
       "      <td>-556.662407</td>\n",
       "      <td>327.948578</td>\n",
       "      <td>403.045493</td>\n",
       "      <td>-470.432027</td>\n",
       "      <td>-47.486762</td>\n",
       "      <td>-196.501412</td>\n",
       "      <td>193.507067</td>\n",
       "      <td>-243.037107</td>\n",
       "      <td>18.220247</td>\n",
       "      <td>-535.020750</td>\n",
       "      <td>...</td>\n",
       "      <td>37.022675</td>\n",
       "      <td>109.140112</td>\n",
       "      <td>281.746197</td>\n",
       "      <td>-86.577918</td>\n",
       "      <td>240.693865</td>\n",
       "      <td>228.508012</td>\n",
       "      <td>206.300212</td>\n",
       "      <td>160.763980</td>\n",
       "      <td>86.301625</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9982</td>\n",
       "      <td>-488.087381</td>\n",
       "      <td>-26.429104</td>\n",
       "      <td>383.020445</td>\n",
       "      <td>-41.025981</td>\n",
       "      <td>465.878932</td>\n",
       "      <td>339.558754</td>\n",
       "      <td>38.989980</td>\n",
       "      <td>34.131853</td>\n",
       "      <td>561.170572</td>\n",
       "      <td>-143.226103</td>\n",
       "      <td>...</td>\n",
       "      <td>-402.845126</td>\n",
       "      <td>-286.429064</td>\n",
       "      <td>108.802784</td>\n",
       "      <td>-112.599897</td>\n",
       "      <td>405.605532</td>\n",
       "      <td>22.144861</td>\n",
       "      <td>127.117273</td>\n",
       "      <td>108.833129</td>\n",
       "      <td>-415.421201</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9983</td>\n",
       "      <td>-912.867122</td>\n",
       "      <td>-526.050723</td>\n",
       "      <td>53.051639</td>\n",
       "      <td>187.479578</td>\n",
       "      <td>-430.192070</td>\n",
       "      <td>-161.147972</td>\n",
       "      <td>22.003299</td>\n",
       "      <td>-0.047729</td>\n",
       "      <td>190.139550</td>\n",
       "      <td>-82.424509</td>\n",
       "      <td>...</td>\n",
       "      <td>132.489614</td>\n",
       "      <td>1.013455</td>\n",
       "      <td>-61.100705</td>\n",
       "      <td>-11.238052</td>\n",
       "      <td>13.919127</td>\n",
       "      <td>-20.947867</td>\n",
       "      <td>-117.209844</td>\n",
       "      <td>1.778703</td>\n",
       "      <td>16.743361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9984</td>\n",
       "      <td>-968.118530</td>\n",
       "      <td>-563.215230</td>\n",
       "      <td>43.438944</td>\n",
       "      <td>30.902876</td>\n",
       "      <td>-358.516912</td>\n",
       "      <td>-145.296152</td>\n",
       "      <td>101.798531</td>\n",
       "      <td>-36.616106</td>\n",
       "      <td>290.462219</td>\n",
       "      <td>-69.836224</td>\n",
       "      <td>...</td>\n",
       "      <td>4.498115</td>\n",
       "      <td>115.925140</td>\n",
       "      <td>-70.214624</td>\n",
       "      <td>-49.808995</td>\n",
       "      <td>51.797224</td>\n",
       "      <td>-79.761193</td>\n",
       "      <td>-69.205383</td>\n",
       "      <td>3.694091</td>\n",
       "      <td>80.934494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9985</td>\n",
       "      <td>179.527500</td>\n",
       "      <td>888.466472</td>\n",
       "      <td>-681.880837</td>\n",
       "      <td>27.373448</td>\n",
       "      <td>488.215638</td>\n",
       "      <td>277.162495</td>\n",
       "      <td>-620.209139</td>\n",
       "      <td>206.865627</td>\n",
       "      <td>-103.616930</td>\n",
       "      <td>-93.749304</td>\n",
       "      <td>...</td>\n",
       "      <td>122.145357</td>\n",
       "      <td>27.429961</td>\n",
       "      <td>-326.540044</td>\n",
       "      <td>-166.598616</td>\n",
       "      <td>-55.097949</td>\n",
       "      <td>97.250869</td>\n",
       "      <td>-186.735006</td>\n",
       "      <td>46.383846</td>\n",
       "      <td>130.067937</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9986</td>\n",
       "      <td>-180.357881</td>\n",
       "      <td>-174.794123</td>\n",
       "      <td>-489.900336</td>\n",
       "      <td>-131.281480</td>\n",
       "      <td>649.462053</td>\n",
       "      <td>-688.275016</td>\n",
       "      <td>791.816047</td>\n",
       "      <td>15.812364</td>\n",
       "      <td>-227.619619</td>\n",
       "      <td>-108.439697</td>\n",
       "      <td>...</td>\n",
       "      <td>21.784375</td>\n",
       "      <td>238.005413</td>\n",
       "      <td>-105.507906</td>\n",
       "      <td>30.025496</td>\n",
       "      <td>-255.281461</td>\n",
       "      <td>247.626172</td>\n",
       "      <td>-147.338860</td>\n",
       "      <td>242.372678</td>\n",
       "      <td>-226.546382</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9987</td>\n",
       "      <td>-973.034566</td>\n",
       "      <td>-584.631059</td>\n",
       "      <td>123.402916</td>\n",
       "      <td>-79.102610</td>\n",
       "      <td>-229.775087</td>\n",
       "      <td>59.257651</td>\n",
       "      <td>398.989902</td>\n",
       "      <td>-164.621960</td>\n",
       "      <td>442.179216</td>\n",
       "      <td>-64.156812</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.770839</td>\n",
       "      <td>47.337766</td>\n",
       "      <td>-128.052339</td>\n",
       "      <td>-197.314093</td>\n",
       "      <td>16.254381</td>\n",
       "      <td>-89.789911</td>\n",
       "      <td>18.265664</td>\n",
       "      <td>81.706012</td>\n",
       "      <td>145.834954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9988</td>\n",
       "      <td>71.472776</td>\n",
       "      <td>1065.004927</td>\n",
       "      <td>250.862057</td>\n",
       "      <td>-16.601793</td>\n",
       "      <td>169.046593</td>\n",
       "      <td>217.480176</td>\n",
       "      <td>-532.394225</td>\n",
       "      <td>-51.705202</td>\n",
       "      <td>-89.228428</td>\n",
       "      <td>-172.770797</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.117537</td>\n",
       "      <td>147.853836</td>\n",
       "      <td>191.141347</td>\n",
       "      <td>-51.493097</td>\n",
       "      <td>9.752980</td>\n",
       "      <td>118.595394</td>\n",
       "      <td>42.700016</td>\n",
       "      <td>-161.550893</td>\n",
       "      <td>-151.801910</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9989</td>\n",
       "      <td>242.160565</td>\n",
       "      <td>-123.242654</td>\n",
       "      <td>-803.600452</td>\n",
       "      <td>-131.426098</td>\n",
       "      <td>-228.074583</td>\n",
       "      <td>315.422082</td>\n",
       "      <td>-72.319157</td>\n",
       "      <td>-58.518711</td>\n",
       "      <td>152.071552</td>\n",
       "      <td>-566.894041</td>\n",
       "      <td>...</td>\n",
       "      <td>-173.664672</td>\n",
       "      <td>183.778729</td>\n",
       "      <td>-332.408136</td>\n",
       "      <td>389.453698</td>\n",
       "      <td>184.983270</td>\n",
       "      <td>-118.430080</td>\n",
       "      <td>-239.374659</td>\n",
       "      <td>200.937563</td>\n",
       "      <td>38.274112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9990</td>\n",
       "      <td>1044.818136</td>\n",
       "      <td>-138.889580</td>\n",
       "      <td>-72.422438</td>\n",
       "      <td>-717.069699</td>\n",
       "      <td>-730.943613</td>\n",
       "      <td>-51.390704</td>\n",
       "      <td>-213.990146</td>\n",
       "      <td>78.323713</td>\n",
       "      <td>259.352258</td>\n",
       "      <td>269.750737</td>\n",
       "      <td>...</td>\n",
       "      <td>-431.754956</td>\n",
       "      <td>210.854442</td>\n",
       "      <td>-45.900930</td>\n",
       "      <td>-46.861096</td>\n",
       "      <td>170.789433</td>\n",
       "      <td>49.126263</td>\n",
       "      <td>-45.276366</td>\n",
       "      <td>-165.965799</td>\n",
       "      <td>240.823399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9991</td>\n",
       "      <td>1459.127244</td>\n",
       "      <td>-94.098461</td>\n",
       "      <td>401.352840</td>\n",
       "      <td>-16.251029</td>\n",
       "      <td>-394.698839</td>\n",
       "      <td>450.651818</td>\n",
       "      <td>-296.043712</td>\n",
       "      <td>-239.286926</td>\n",
       "      <td>21.762329</td>\n",
       "      <td>-210.234403</td>\n",
       "      <td>...</td>\n",
       "      <td>25.221273</td>\n",
       "      <td>-206.085981</td>\n",
       "      <td>-15.570773</td>\n",
       "      <td>47.831574</td>\n",
       "      <td>186.961106</td>\n",
       "      <td>-27.822246</td>\n",
       "      <td>-82.886112</td>\n",
       "      <td>33.511913</td>\n",
       "      <td>-16.968259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9992</td>\n",
       "      <td>129.628823</td>\n",
       "      <td>568.381067</td>\n",
       "      <td>-590.370260</td>\n",
       "      <td>376.136817</td>\n",
       "      <td>228.374638</td>\n",
       "      <td>43.421807</td>\n",
       "      <td>-499.933383</td>\n",
       "      <td>11.035317</td>\n",
       "      <td>190.660812</td>\n",
       "      <td>277.698297</td>\n",
       "      <td>...</td>\n",
       "      <td>255.456043</td>\n",
       "      <td>327.891494</td>\n",
       "      <td>-282.665467</td>\n",
       "      <td>-299.357479</td>\n",
       "      <td>-63.470040</td>\n",
       "      <td>-463.760050</td>\n",
       "      <td>255.584510</td>\n",
       "      <td>295.277559</td>\n",
       "      <td>54.287459</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9993</td>\n",
       "      <td>-733.927501</td>\n",
       "      <td>-560.937392</td>\n",
       "      <td>247.096215</td>\n",
       "      <td>123.110536</td>\n",
       "      <td>140.745410</td>\n",
       "      <td>-660.280651</td>\n",
       "      <td>-444.553882</td>\n",
       "      <td>170.092457</td>\n",
       "      <td>221.493418</td>\n",
       "      <td>221.825238</td>\n",
       "      <td>...</td>\n",
       "      <td>51.744302</td>\n",
       "      <td>-31.136731</td>\n",
       "      <td>92.322321</td>\n",
       "      <td>216.559245</td>\n",
       "      <td>-227.804446</td>\n",
       "      <td>120.001978</td>\n",
       "      <td>-12.346692</td>\n",
       "      <td>-198.411768</td>\n",
       "      <td>-105.524168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9994</td>\n",
       "      <td>-430.432830</td>\n",
       "      <td>831.595986</td>\n",
       "      <td>-325.745383</td>\n",
       "      <td>-272.734414</td>\n",
       "      <td>-176.758087</td>\n",
       "      <td>-220.506408</td>\n",
       "      <td>285.041088</td>\n",
       "      <td>212.897483</td>\n",
       "      <td>-442.550622</td>\n",
       "      <td>328.100990</td>\n",
       "      <td>...</td>\n",
       "      <td>270.818007</td>\n",
       "      <td>-21.205845</td>\n",
       "      <td>176.403887</td>\n",
       "      <td>274.894545</td>\n",
       "      <td>16.586350</td>\n",
       "      <td>118.814316</td>\n",
       "      <td>-85.788540</td>\n",
       "      <td>-204.014350</td>\n",
       "      <td>-116.620979</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>-949.656129</td>\n",
       "      <td>-395.625023</td>\n",
       "      <td>-17.908384</td>\n",
       "      <td>-112.495228</td>\n",
       "      <td>-442.782935</td>\n",
       "      <td>90.019601</td>\n",
       "      <td>436.826800</td>\n",
       "      <td>-218.034562</td>\n",
       "      <td>236.829387</td>\n",
       "      <td>21.153725</td>\n",
       "      <td>...</td>\n",
       "      <td>-180.376762</td>\n",
       "      <td>78.216092</td>\n",
       "      <td>-98.960142</td>\n",
       "      <td>-145.575051</td>\n",
       "      <td>71.367965</td>\n",
       "      <td>-73.993048</td>\n",
       "      <td>-72.063413</td>\n",
       "      <td>8.018811</td>\n",
       "      <td>235.049755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>1740.723347</td>\n",
       "      <td>-358.986516</td>\n",
       "      <td>86.931913</td>\n",
       "      <td>-186.198414</td>\n",
       "      <td>-701.729650</td>\n",
       "      <td>-455.164341</td>\n",
       "      <td>226.614327</td>\n",
       "      <td>-400.774892</td>\n",
       "      <td>-282.159978</td>\n",
       "      <td>513.409119</td>\n",
       "      <td>...</td>\n",
       "      <td>146.515632</td>\n",
       "      <td>-67.793287</td>\n",
       "      <td>63.044005</td>\n",
       "      <td>17.806563</td>\n",
       "      <td>117.524131</td>\n",
       "      <td>17.936177</td>\n",
       "      <td>185.854834</td>\n",
       "      <td>-62.535360</td>\n",
       "      <td>-162.228896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>-131.235854</td>\n",
       "      <td>298.223209</td>\n",
       "      <td>562.865979</td>\n",
       "      <td>88.325936</td>\n",
       "      <td>507.168096</td>\n",
       "      <td>414.011695</td>\n",
       "      <td>-200.209541</td>\n",
       "      <td>270.389411</td>\n",
       "      <td>526.035095</td>\n",
       "      <td>-171.648404</td>\n",
       "      <td>...</td>\n",
       "      <td>-369.855005</td>\n",
       "      <td>65.111148</td>\n",
       "      <td>448.972025</td>\n",
       "      <td>446.188182</td>\n",
       "      <td>254.971808</td>\n",
       "      <td>-27.574150</td>\n",
       "      <td>48.506134</td>\n",
       "      <td>-59.725599</td>\n",
       "      <td>-281.568489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>924.615974</td>\n",
       "      <td>-920.620145</td>\n",
       "      <td>-289.510976</td>\n",
       "      <td>-381.102254</td>\n",
       "      <td>349.559934</td>\n",
       "      <td>199.683773</td>\n",
       "      <td>607.756033</td>\n",
       "      <td>558.771585</td>\n",
       "      <td>15.139195</td>\n",
       "      <td>-323.630581</td>\n",
       "      <td>...</td>\n",
       "      <td>-356.245796</td>\n",
       "      <td>138.842624</td>\n",
       "      <td>-145.750045</td>\n",
       "      <td>-129.613558</td>\n",
       "      <td>-74.780753</td>\n",
       "      <td>17.143166</td>\n",
       "      <td>-4.389063</td>\n",
       "      <td>-151.888140</td>\n",
       "      <td>443.788705</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>-967.484298</td>\n",
       "      <td>-424.181084</td>\n",
       "      <td>80.511024</td>\n",
       "      <td>56.062986</td>\n",
       "      <td>-408.440234</td>\n",
       "      <td>137.900633</td>\n",
       "      <td>396.410046</td>\n",
       "      <td>-213.911252</td>\n",
       "      <td>137.096255</td>\n",
       "      <td>56.316511</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.628172</td>\n",
       "      <td>206.048589</td>\n",
       "      <td>-16.356439</td>\n",
       "      <td>-101.830569</td>\n",
       "      <td>27.563268</td>\n",
       "      <td>-48.357885</td>\n",
       "      <td>-182.843523</td>\n",
       "      <td>-35.207401</td>\n",
       "      <td>205.259876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1           f2          f3          f4          f5  \\\n",
       "9980  -162.771692   935.535743  210.969540 -614.882063  301.029607   \n",
       "9981  -556.662407   327.948578  403.045493 -470.432027  -47.486762   \n",
       "9982  -488.087381   -26.429104  383.020445  -41.025981  465.878932   \n",
       "9983  -912.867122  -526.050723   53.051639  187.479578 -430.192070   \n",
       "9984  -968.118530  -563.215230   43.438944   30.902876 -358.516912   \n",
       "9985   179.527500   888.466472 -681.880837   27.373448  488.215638   \n",
       "9986  -180.357881  -174.794123 -489.900336 -131.281480  649.462053   \n",
       "9987  -973.034566  -584.631059  123.402916  -79.102610 -229.775087   \n",
       "9988    71.472776  1065.004927  250.862057  -16.601793  169.046593   \n",
       "9989   242.160565  -123.242654 -803.600452 -131.426098 -228.074583   \n",
       "9990  1044.818136  -138.889580  -72.422438 -717.069699 -730.943613   \n",
       "9991  1459.127244   -94.098461  401.352840  -16.251029 -394.698839   \n",
       "9992   129.628823   568.381067 -590.370260  376.136817  228.374638   \n",
       "9993  -733.927501  -560.937392  247.096215  123.110536  140.745410   \n",
       "9994  -430.432830   831.595986 -325.745383 -272.734414 -176.758087   \n",
       "9995  -949.656129  -395.625023  -17.908384 -112.495228 -442.782935   \n",
       "9996  1740.723347  -358.986516   86.931913 -186.198414 -701.729650   \n",
       "9997  -131.235854   298.223209  562.865979   88.325936  507.168096   \n",
       "9998   924.615974  -920.620145 -289.510976 -381.102254  349.559934   \n",
       "9999  -967.484298  -424.181084   80.511024   56.062986 -408.440234   \n",
       "\n",
       "              f6          f7          f8          f9         f10  ...  \\\n",
       "9980  214.300365 -182.519084  179.170125   65.932431 -158.061641  ...   \n",
       "9981 -196.501412  193.507067 -243.037107   18.220247 -535.020750  ...   \n",
       "9982  339.558754   38.989980   34.131853  561.170572 -143.226103  ...   \n",
       "9983 -161.147972   22.003299   -0.047729  190.139550  -82.424509  ...   \n",
       "9984 -145.296152  101.798531  -36.616106  290.462219  -69.836224  ...   \n",
       "9985  277.162495 -620.209139  206.865627 -103.616930  -93.749304  ...   \n",
       "9986 -688.275016  791.816047   15.812364 -227.619619 -108.439697  ...   \n",
       "9987   59.257651  398.989902 -164.621960  442.179216  -64.156812  ...   \n",
       "9988  217.480176 -532.394225  -51.705202  -89.228428 -172.770797  ...   \n",
       "9989  315.422082  -72.319157  -58.518711  152.071552 -566.894041  ...   \n",
       "9990  -51.390704 -213.990146   78.323713  259.352258  269.750737  ...   \n",
       "9991  450.651818 -296.043712 -239.286926   21.762329 -210.234403  ...   \n",
       "9992   43.421807 -499.933383   11.035317  190.660812  277.698297  ...   \n",
       "9993 -660.280651 -444.553882  170.092457  221.493418  221.825238  ...   \n",
       "9994 -220.506408  285.041088  212.897483 -442.550622  328.100990  ...   \n",
       "9995   90.019601  436.826800 -218.034562  236.829387   21.153725  ...   \n",
       "9996 -455.164341  226.614327 -400.774892 -282.159978  513.409119  ...   \n",
       "9997  414.011695 -200.209541  270.389411  526.035095 -171.648404  ...   \n",
       "9998  199.683773  607.756033  558.771585   15.139195 -323.630581  ...   \n",
       "9999  137.900633  396.410046 -213.911252  137.096255   56.316511  ...   \n",
       "\n",
       "             f17         f18         f19         f20         f21         f22  \\\n",
       "9980  102.574200  -59.288106  -45.326482 -173.349505  -31.392617  172.690845   \n",
       "9981   37.022675  109.140112  281.746197  -86.577918  240.693865  228.508012   \n",
       "9982 -402.845126 -286.429064  108.802784 -112.599897  405.605532   22.144861   \n",
       "9983  132.489614    1.013455  -61.100705  -11.238052   13.919127  -20.947867   \n",
       "9984    4.498115  115.925140  -70.214624  -49.808995   51.797224  -79.761193   \n",
       "9985  122.145357   27.429961 -326.540044 -166.598616  -55.097949   97.250869   \n",
       "9986   21.784375  238.005413 -105.507906   30.025496 -255.281461  247.626172   \n",
       "9987  -17.770839   47.337766 -128.052339 -197.314093   16.254381  -89.789911   \n",
       "9988  -32.117537  147.853836  191.141347  -51.493097    9.752980  118.595394   \n",
       "9989 -173.664672  183.778729 -332.408136  389.453698  184.983270 -118.430080   \n",
       "9990 -431.754956  210.854442  -45.900930  -46.861096  170.789433   49.126263   \n",
       "9991   25.221273 -206.085981  -15.570773   47.831574  186.961106  -27.822246   \n",
       "9992  255.456043  327.891494 -282.665467 -299.357479  -63.470040 -463.760050   \n",
       "9993   51.744302  -31.136731   92.322321  216.559245 -227.804446  120.001978   \n",
       "9994  270.818007  -21.205845  176.403887  274.894545   16.586350  118.814316   \n",
       "9995 -180.376762   78.216092  -98.960142 -145.575051   71.367965  -73.993048   \n",
       "9996  146.515632  -67.793287   63.044005   17.806563  117.524131   17.936177   \n",
       "9997 -369.855005   65.111148  448.972025  446.188182  254.971808  -27.574150   \n",
       "9998 -356.245796  138.842624 -145.750045 -129.613558  -74.780753   17.143166   \n",
       "9999  -26.628172  206.048589  -16.356439 -101.830569   27.563268  -48.357885   \n",
       "\n",
       "             f23         f24         f25  Label  \n",
       "9980  -24.677229 -261.011283  110.302253      9  \n",
       "9981  206.300212  160.763980   86.301625      7  \n",
       "9982  127.117273  108.833129 -415.421201      4  \n",
       "9983 -117.209844    1.778703   16.743361      1  \n",
       "9984  -69.205383    3.694091   80.934494      1  \n",
       "9985 -186.735006   46.383846  130.067937      4  \n",
       "9986 -147.338860  242.372678 -226.546382      2  \n",
       "9987   18.265664   81.706012  145.834954      1  \n",
       "9988   42.700016 -161.550893 -151.801910      4  \n",
       "9989 -239.374659  200.937563   38.274112      5  \n",
       "9990  -45.276366 -165.965799  240.823399      0  \n",
       "9991  -82.886112   33.511913  -16.968259      0  \n",
       "9992  255.584510  295.277559   54.287459      9  \n",
       "9993  -12.346692 -198.411768 -105.524168      1  \n",
       "9994  -85.788540 -204.014350 -116.620979      7  \n",
       "9995  -72.063413    8.018811  235.049755      1  \n",
       "9996  185.854834  -62.535360 -162.228896      0  \n",
       "9997   48.506134  -59.725599 -281.568489      4  \n",
       "9998   -4.389063 -151.888140  443.788705      3  \n",
       "9999 -182.843523  -35.207401  205.259876      1  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns1=[]\n",
    "columns2=[]\n",
    "for i in range(0,25):\n",
    "    s=str('f')+str(i+1)\n",
    "    columns1.append(s)\n",
    "    columns2.append(s)\n",
    "columns1.append('Label')\n",
    "columns2.append('Label')\n",
    "df= pd.read_csv('train_set.csv',sep=',', names=columns1)\n",
    "df1= pd.read_csv('test_set.csv',sep=',', names=columns2)\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Cross Validation on the training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.8% (1956/2000) (classification)\n",
      "iter-value: 0 ,Accuracy: (97.8, 0.3855, 0.9554613165697751)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for iter in range(0,200):\n",
    "    label=(df['Label']).values.tolist() #storing the label vector into a list\n",
    "    features=[]\n",
    "    dict={}\n",
    "    feature_data=[]\n",
    "    for i in range(1,26):\n",
    "        s=str('f')+str(i)\n",
    "        features.append((df[s]).values.tolist())\n",
    "    def libsvm_format(features): #function which transforms the dataset to be train into format required by LIBSVM\n",
    "        for i in range(0,len(features[0])):\n",
    "            dict={}\n",
    "            for j in range(0,len(features)):\n",
    "                dict[j+1]=features[j][i]\n",
    "            feature_data.append(dict)\n",
    "        return feature_data\n",
    "\n",
    "    x=np.transpose(features[0:25])      \n",
    "#X=np.transpose(x)\n",
    "    y=label\n",
    "    X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.20) #performing split of training and testing data\n",
    "    t=libsvm_format(np.transpose(X_test)) #Bringing data to be testest into desired format for LIBSVM\n",
    "    problem=svm_problem(y_train,X_train)\n",
    "    param='-s 0 -t 2 -g 1.2216773489967931e-06'\n",
    "    m = svm_train(y_train,X_train,param)\n",
    "    predicted_labels,a,b= svm_predict(y_test,t,m) \n",
    "    print(\"iter-value:\",iter,\",Accuracy:\",a)\n",
    "    print(\"-----------------------------------------\")\n",
    "    if(a[0]>=97.8):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.) Performing SVM classification using Polynomial Kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) when degree=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the gamma parameter of polynomial kernel expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "g-value: 1e-08 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "g-value: 1.6496480740980205e-08 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "g-value: 2.7213387683753087e-08 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 13% (260/2000) (classification)\n",
      "g-value: 4.4892512582186074e-08 ,Accuracy: (13.0, 21.7305, 0.0009463697886200212)\n",
      "-----------------------------------------\n",
      "Accuracy = 45.8% (916/2000) (classification)\n",
      "g-value: 7.405684692262443e-08 ,Accuracy: (45.800000000000004, 10.0705, 0.2553125776589585)\n",
      "-----------------------------------------\n",
      "Accuracy = 83.4% (1668/2000) (classification)\n",
      "g-value: 1.221677348996793e-07 ,Accuracy: (83.39999999999999, 3.087, 0.7036836460891123)\n",
      "-----------------------------------------\n",
      "Accuracy = 93.3% (1866/2000) (classification)\n",
      "g-value: 2.015337685941735e-07 ,Accuracy: (93.30000000000001, 1.111, 0.8764102997259449)\n",
      "-----------------------------------------\n",
      "Accuracy = 95.85% (1917/2000) (classification)\n",
      "g-value: 3.324597932270938e-07 ,Accuracy: (95.85000000000001, 0.702, 0.9194580596949575)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.8% (1936/2000) (classification)\n",
      "g-value: 5.484416576121015e-07 ,Accuracy: (96.8, 0.601, 0.9306860232764139)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.75% (1935/2000) (classification)\n",
      "g-value: 9.047357242349293e-07 ,Accuracy: (96.75, 0.5225, 0.9396198260688864)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.65% (1933/2000) (classification)\n",
      "g-value: 1.492495545051829e-06 ,Accuracy: (96.65, 0.5575, 0.9357780317055623)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 2.4620924014946257e-06 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 4.061585988376979e-06 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 6.70018750350959e-06 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 1.1052951411260198e-05 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 1.8233480008684384e-05 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 3.007882518043096e-05 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 4.961947603002898e-05 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 8.185467307069021e-05 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.00013503140378698722 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.00022275429519995563 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.0003674661940736688 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.0006061898993497572 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.001 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.0016496480740980208 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.002721338768375309 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.004489251258218608 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.007405684692262427 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.012216773489967905 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.02015337685941731 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.03324597932270938 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.05484416576121015 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.09047357242349294 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.1492495545051829 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.24620924014946255 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.40615859883769795 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 0.670018750350959 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 1.10529514112602 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 1.8233480008684386 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 3.007882518043096 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 4.961947603002898 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 8.18546730706902 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 13.503140378698722 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 22.275429519995562 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 36.74661940736688 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "g-value: 60.61898993497572 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-9c438a7a37d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mparam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-s 0 -t 1 -d 3 -g '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m    \u001b[1;31m#+' -c '+str(6.614740641230159e-15)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msvm_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"g-value:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\",Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\libsvm\\svmutil.py\u001b[0m in \u001b[0;36msvm_predict\u001b[1;34m(y, x, m, options)\u001b[0m\n\u001b[0;32m    236\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                                 \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_svm_nodearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misKernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPRECOMPUTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m                         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_predict_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m                         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnr_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c_=np.logspace(-2,5,40)\n",
    "g_=np.logspace(-8,7,70)\n",
    "for i in range(len(g_)):\n",
    "    problem=svm_problem(y_train,X_train)\n",
    "    param='-s 0 -t 1 -d 3 -g '+str(g_[i] )    #+' -c '+str(6.614740641230159e-15)\n",
    "    m = svm_train(y_train,X_train,param)\n",
    "    predicted_labels,a,b= svm_predict(y_test,t,m) \n",
    "    print(\"g-value:\",g_[i],\",Accuracy:\",a)\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameter C(cost or penalty on classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "C-value: 1e-05 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "C-value: 1.80472176682717e-05 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "C-value: 3.257020655659783e-05 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "C-value: 5.878016072274912e-05 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "C-value: 0.00010608183551394483 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "C-value: 0.00019144819761699575 ,Accuracy: (10.85, 21.656, 0.0012489114060884072)\n",
      "-----------------------------------------\n",
      "Accuracy = 11.45% (229/2000) (classification)\n",
      "C-value: 0.0003455107294592218 ,Accuracy: (11.450000000000001, 21.674, 0.0)\n",
      "-----------------------------------------\n",
      "Accuracy = 13.35% (267/2000) (classification)\n",
      "C-value: 0.0006235507341273912 ,Accuracy: (13.350000000000001, 21.679, 0.008116464982694629)\n",
      "-----------------------------------------\n",
      "Accuracy = 15.9% (318/2000) (classification)\n",
      "C-value: 0.0011253355826007646 ,Accuracy: (15.9, 21.6545, 0.00027482474657121664)\n",
      "-----------------------------------------\n",
      "Accuracy = 36.85% (737/2000) (classification)\n",
      "C-value: 0.002030917620904735 ,Accuracy: (36.85, 15.3575, 0.10007006741782348)\n",
      "-----------------------------------------\n",
      "Accuracy = 61.6% (1232/2000) (classification)\n",
      "C-value: 0.003665241237079626 ,Accuracy: (61.6, 6.282, 0.4831631158072149)\n",
      "-----------------------------------------\n",
      "Accuracy = 76.45% (1529/2000) (classification)\n",
      "C-value: 0.006614740641230145 ,Accuracy: (76.44999999999999, 5.5165, 0.5688346587146456)\n",
      "-----------------------------------------\n",
      "Accuracy = 84.15% (1683/2000) (classification)\n",
      "C-value: 0.011937766417144358 ,Accuracy: (84.15, 2.8835, 0.7186024390938006)\n",
      "-----------------------------------------\n",
      "Accuracy = 88.85% (1777/2000) (classification)\n",
      "C-value: 0.021544346900318822 ,Accuracy: (88.85, 2.027, 0.7899646710256437)\n",
      "-----------------------------------------\n",
      "Accuracy = 92.65% (1853/2000) (classification)\n",
      "C-value: 0.03888155180308085 ,Accuracy: (92.65, 1.3055, 0.8574867129498298)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.15% (1883/2000) (classification)\n",
      "C-value: 0.07017038286703822 ,Accuracy: (94.15, 0.9685, 0.8909755196395593)\n",
      "-----------------------------------------\n",
      "Accuracy = 95.15% (1903/2000) (classification)\n",
      "C-value: 0.1266380173467402 ,Accuracy: (95.15, 0.774, 0.9118225411081858)\n",
      "-----------------------------------------\n",
      "Accuracy = 95.9% (1918/2000) (classification)\n",
      "C-value: 0.22854638641349884 ,Accuracy: (95.89999999999999, 0.7015, 0.9195085697370982)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.45% (1929/2000) (classification)\n",
      "C-value: 0.4124626382901348 ,Accuracy: (96.45, 0.679, 0.9219679300229183)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.65% (1933/2000) (classification)\n",
      "C-value: 0.7443803013251681 ,Accuracy: (96.65, 0.611, 0.9295886981865257)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.05% (1941/2000) (classification)\n",
      "C-value: 1.3433993325988987 ,Accuracy: (97.05, 0.5585, 0.9356026738654167)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.8% (1936/2000) (classification)\n",
      "C-value: 2.424462017082326 ,Accuracy: (96.8, 0.54, 0.937633428425247)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.75% (1935/2000) (classification)\n",
      "C-value: 4.37547937507418 ,Accuracy: (96.75, 0.5225, 0.9396198260688864)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.55% (1931/2000) (classification)\n",
      "C-value: 7.896522868499717 ,Accuracy: (96.55, 0.5795, 0.9332238499067008)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 14.251026703029963 ,Accuracy: (96.7, 0.5555, 0.9359958023802813)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 25.719138090593418 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 46.41588833612773 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 83.76776400682907 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 151.177507061566 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 272.8333376486764 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 492.38826317067316 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 888.6238162743389 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 1603.7187437513276 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 2894.26612471674 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 5223.345074266833 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 9426.684551178854 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 17012.542798525858 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 30702.906297578375 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 55410.20330009481 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.7% (1934/2000) (classification)\n",
      "C-value: 100000.0 ,Accuracy: (96.7, 0.545, 0.9372178171599244)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "c_=np.logspace(-5,5,40)\n",
    "g_=np.logspace(-9,3,13)\n",
    "for i in range(len(c_)):\n",
    "    problem=svm_problem(y_train,X_train) #initializing the svm problem\n",
    "    param='-s 0 -t 1 -d 3 -g 5.484416576121015e-07 -c '+str(c_[i])\n",
    "    m = svm_train(y_train,X_train,param) #training the model\n",
    "    predicted_labels,a,b= svm_predict(y_test,t,m)  #predicting the value of the test dataset\n",
    "    print(\"C-value:\",c_[i],\",Accuracy:\",a) #displaying the parameters\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.05% (1941/2000) (classification)\n"
     ]
    }
   ],
   "source": [
    "problem=svm_problem(y_train,X_train)\n",
    "param='-s 0 -t 1 -d 3 -g 5.484416576121015e-07 -c '+str(1.3433993325988987)\n",
    "m = svm_train(y_train,X_train,param)\n",
    "predicted_labels,a,b= svm_predict(y_test,t,m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 9.7% (194/2000) (classification)\n"
     ]
    }
   ],
   "source": [
    "#label=(df['Label']).values.tolist()\n",
    "features1=[]\n",
    "dict={}\n",
    "feature_data1=[]\n",
    "t1=[]\n",
    "x1=[]\n",
    "for i in range(1,26):\n",
    "    s=str('f')+str(i)\n",
    "    features1.append((df1[s]).values.tolist())\n",
    "def libsvm_format(features1):\n",
    "    for i in range(0,len(features1[0])):\n",
    "        dict={}\n",
    "        for j in range(0,len(features1)):\n",
    "            dict[j+1]=features1[j][i]\n",
    "        feature_data1.append(dict)\n",
    "    return feature_data1\n",
    "x1=np.transpose(features1[0:25])      \n",
    "#y1=label\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "len(features1[0]),len(t1),len(x1)\n",
    "t1=libsvm_format(np.transpose(x1))\n",
    "c_=np.logspace(-15,10,16)\n",
    "g_=np.logspace(-9,3,13)\n",
    "\n",
    "problem=svm_problem(y,x)\n",
    "#param='-s 0 -t 2 -g '+str(1e-06)+' -c '+str(1.9306977288832496)\n",
    "param='-s 0 -t 1 -d 3 -g 5.484416576121015e-07 -c '+str(1.3433993325988987)\n",
    "m = svm_train(y,x,param)\n",
    "predicted_labels,a,b= svm_predict([],t1,m)\n",
    "output=predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id class\n",
       "0        0     3\n",
       "1        1     5\n",
       "2        2     2\n",
       "3        3     7\n",
       "4        4     6\n",
       "...    ...   ...\n",
       "1995  1995     8\n",
       "1996  1996     1\n",
       "1997  1997     7\n",
       "1998  1998     2\n",
       "1999  1999     5\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out1=pd.DataFrame({'id':str(0),'class':str(int(output[0]))},index=[0])\n",
    "for i in range(1,len(output)):\n",
    "    df_out1=df_out1.append({'id':str(i),'class':str(int(output[i]))},ignore_index=True)\n",
    "df_out1.to_csv('submission5.csv',index=False)\n",
    "df_out1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) when degree=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "g-value: 1e-09 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "g-value: 1e-08 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 16.25% (325/2000) (classification)\n",
      "g-value: 1e-07 ,Accuracy: (16.25, 21.5385, 0.005659927154930114)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.95% (1899/2000) (classification)\n",
      "g-value: 1e-06 ,Accuracy: (94.95, 0.939, 0.8926474933067137)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 1e-05 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 0.0001 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 0.001 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 0.01 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 0.1 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 1.0 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 10.0 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.75% (1895/2000) (classification)\n",
      "g-value: 100.0 ,Accuracy: (94.75, 0.963, 0.889984160262992)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.05% (1881/2000) (classification)\n",
      "g-value: 1000.0 ,Accuracy: (94.05, 1.069, 0.877890296922963)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "c_=np.logspace(-15,10,13)\n",
    "g_=np.logspace(-9,3,13)\n",
    "for i in range(len(c_)):\n",
    "    problem=svm_problem(y_train,X_train)\n",
    "    param='-s 0 -t 1 -d 4 -g '+str(g_[i])\n",
    "    m = svm_train(y_train,X_train,param)\n",
    "    predicted_labels,a,b= svm_predict(y_test,t,m) \n",
    "    print(\"g-value:\",g_[i],\",Accuracy:\",a)\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.) (a)Performing SVM classification using RBF Kernel and also Tuning the hyperparameter g (gamma value in the expression for rbf kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.4% (1788/2000) (classification)\n",
      "gamma-value: 1e-08 ,Accuracy: (89.4, 1.8665, 0.7931154814811792)\n",
      "-----------------------------------------\n",
      "Accuracy = 90.1% (1802/2000) (classification)\n",
      "gamma-value: 1.221677348996793e-08 ,Accuracy: (90.10000000000001, 1.7075, 0.8095703484602881)\n",
      "-----------------------------------------\n",
      "Accuracy = 90.25% (1805/2000) (classification)\n",
      "gamma-value: 1.492495545051829e-08 ,Accuracy: (90.25, 1.6985, 0.8103955426509022)\n",
      "-----------------------------------------\n",
      "Accuracy = 90.4% (1808/2000) (classification)\n",
      "gamma-value: 1.8233480008684423e-08 ,Accuracy: (90.4, 1.676, 0.8132967002034616)\n",
      "-----------------------------------------\n",
      "Accuracy = 90.6% (1812/2000) (classification)\n",
      "gamma-value: 2.2275429519995565e-08 ,Accuracy: (90.60000000000001, 1.609, 0.8202079773597624)\n",
      "-----------------------------------------\n",
      "Accuracy = 90.85% (1817/2000) (classification)\n",
      "gamma-value: 2.7213387683753087e-08 ,Accuracy: (90.85, 1.545, 0.8270677945232761)\n",
      "-----------------------------------------\n",
      "Accuracy = 91.1% (1822/2000) (classification)\n",
      "gamma-value: 3.3245979322709384e-08 ,Accuracy: (91.10000000000001, 1.5115, 0.8303943097360027)\n",
      "-----------------------------------------\n",
      "Accuracy = 91.55% (1831/2000) (classification)\n",
      "gamma-value: 4.0615859883769794e-08 ,Accuracy: (91.55, 1.463, 0.8353761774100057)\n",
      "-----------------------------------------\n",
      "Accuracy = 92.1% (1842/2000) (classification)\n",
      "gamma-value: 4.961947603002898e-08 ,Accuracy: (92.10000000000001, 1.2995, 0.8528813909273305)\n",
      "-----------------------------------------\n",
      "Accuracy = 92.65% (1853/2000) (classification)\n",
      "gamma-value: 6.061898993497573e-08 ,Accuracy: (92.65, 1.238, 0.8595915716156771)\n",
      "-----------------------------------------\n",
      "Accuracy = 93.05% (1861/2000) (classification)\n",
      "gamma-value: 7.405684692262443e-08 ,Accuracy: (93.05, 1.163, 0.8678798129253698)\n",
      "-----------------------------------------\n",
      "Accuracy = 93.45% (1869/2000) (classification)\n",
      "gamma-value: 9.047357242349293e-08 ,Accuracy: (93.45, 1.12, 0.872722919711405)\n",
      "-----------------------------------------\n",
      "Accuracy = 94% (1880/2000) (classification)\n",
      "gamma-value: 1.1052951411260221e-07 ,Accuracy: (94.0, 1.05, 0.8804763220566301)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.45% (1889/2000) (classification)\n",
      "gamma-value: 1.3503140378698722e-07 ,Accuracy: (94.45, 0.9175, 0.8952622152856969)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.85% (1897/2000) (classification)\n",
      "gamma-value: 1.6496480740980207e-07 ,Accuracy: (94.85, 0.917, 0.895333450714546)\n",
      "-----------------------------------------\n",
      "Accuracy = 95.6% (1912/2000) (classification)\n",
      "gamma-value: 2.015337685941735e-07 ,Accuracy: (95.6, 0.7615, 0.9128344053984196)\n",
      "-----------------------------------------\n",
      "Accuracy = 95.95% (1919/2000) (classification)\n",
      "gamma-value: 2.4620924014946254e-07 ,Accuracy: (95.95, 0.67, 0.9229435711197105)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.3% (1926/2000) (classification)\n",
      "gamma-value: 3.007882518043096e-07 ,Accuracy: (96.3, 0.6385, 0.9265303794128863)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.75% (1935/2000) (classification)\n",
      "gamma-value: 3.674661940736688e-07 ,Accuracy: (96.75, 0.5455, 0.9370353461901239)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.1% (1942/2000) (classification)\n",
      "gamma-value: 4.4892512582186075e-07 ,Accuracy: (97.1, 0.4785, 0.9446755657052107)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.35% (1947/2000) (classification)\n",
      "gamma-value: 5.484416576121015e-07 ,Accuracy: (97.35000000000001, 0.3865, 0.9552288032516483)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.5% (1950/2000) (classification)\n",
      "gamma-value: 6.700187503509591e-07 ,Accuracy: (97.5, 0.3935, 0.9544826361107632)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.75% (1955/2000) (classification)\n",
      "gamma-value: 8.185467307069021e-07 ,Accuracy: (97.75, 0.3425, 0.9603418103998521)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "gamma-value: 1e-06 ,Accuracy: (97.89999999999999, 0.3355, 0.9611933630067309)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.8% (1956/2000) (classification)\n",
      "gamma-value: 1.2216773489967931e-06 ,Accuracy: (97.8, 0.3855, 0.9554613165697751)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.4% (1948/2000) (classification)\n",
      "gamma-value: 1.492495545051829e-06 ,Accuracy: (97.39999999999999, 0.4495, 0.9481358817654296)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.15% (1943/2000) (classification)\n",
      "gamma-value: 1.8233480008684386e-06 ,Accuracy: (97.15, 0.5465, 0.9372288470428918)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.6% (1932/2000) (classification)\n",
      "gamma-value: 2.2275429519995564e-06 ,Accuracy: (96.6, 0.7055, 0.9195972548173638)\n",
      "-----------------------------------------\n",
      "Accuracy = 95.3% (1906/2000) (classification)\n",
      "gamma-value: 2.7213387683753086e-06 ,Accuracy: (95.3, 1.033, 0.8834848545109358)\n",
      "-----------------------------------------\n",
      "Accuracy = 92.5% (1850/2000) (classification)\n",
      "gamma-value: 3.324597932270945e-06 ,Accuracy: (92.5, 1.4765, 0.8375753980854483)\n",
      "-----------------------------------------\n",
      "Accuracy = 87.3% (1746/2000) (classification)\n",
      "gamma-value: 4.061585988376979e-06 ,Accuracy: (87.3, 2.4245, 0.7478233498575048)\n",
      "-----------------------------------------\n",
      "Accuracy = 79.55% (1591/2000) (classification)\n",
      "gamma-value: 4.9619476030028976e-06 ,Accuracy: (79.55, 3.724, 0.6402302129372127)\n",
      "-----------------------------------------\n",
      "Accuracy = 69.65% (1393/2000) (classification)\n",
      "gamma-value: 6.061898993497572e-06 ,Accuracy: (69.65, 5.4745, 0.5137873267686073)\n",
      "-----------------------------------------\n",
      "Accuracy = 58.7% (1174/2000) (classification)\n",
      "gamma-value: 7.405684692262442e-06 ,Accuracy: (58.699999999999996, 7.1885, 0.41078978629967833)\n",
      "-----------------------------------------\n",
      "Accuracy = 48.5% (970/2000) (classification)\n",
      "gamma-value: 9.047357242349294e-06 ,Accuracy: (48.5, 8.9175, 0.3156502802774763)\n",
      "-----------------------------------------\n",
      "Accuracy = 38.4% (768/2000) (classification)\n",
      "gamma-value: 1.1052951411260198e-05 ,Accuracy: (38.4, 10.713, 0.220515088603734)\n",
      "-----------------------------------------\n",
      "Accuracy = 31.65% (633/2000) (classification)\n",
      "gamma-value: 1.3503140378698721e-05 ,Accuracy: (31.65, 12.268, 0.1482714284261295)\n",
      "-----------------------------------------\n",
      "Accuracy = 28.15% (563/2000) (classification)\n",
      "gamma-value: 1.6496480740980206e-05 ,Accuracy: (28.15, 13.146, 0.10620865899293588)\n",
      "-----------------------------------------\n",
      "Accuracy = 19.8% (396/2000) (classification)\n",
      "gamma-value: 2.0153376859417352e-05 ,Accuracy: (19.8, 10.9705, 0.15322930382614255)\n",
      "-----------------------------------------\n",
      "Accuracy = 18.75% (375/2000) (classification)\n",
      "gamma-value: 2.4620924014946254e-05 ,Accuracy: (18.75, 11.186, 0.1408307121175059)\n",
      "-----------------------------------------\n",
      "Accuracy = 18.3% (366/2000) (classification)\n",
      "gamma-value: 3.007882518043096e-05 ,Accuracy: (18.3, 11.316, 0.13404777875174023)\n",
      "-----------------------------------------\n",
      "Accuracy = 17.9% (358/2000) (classification)\n",
      "gamma-value: 3.674661940736688e-05 ,Accuracy: (17.9, 11.444, 0.12783880964482694)\n",
      "-----------------------------------------\n",
      "Accuracy = 17.25% (345/2000) (classification)\n",
      "gamma-value: 4.489251258218608e-05 ,Accuracy: (17.25, 11.678, 0.11622870977698323)\n",
      "-----------------------------------------\n",
      "Accuracy = 17.3% (346/2000) (classification)\n",
      "gamma-value: 5.484416576121015e-05 ,Accuracy: (17.299999999999997, 11.66, 0.1171160263438475)\n",
      "-----------------------------------------\n",
      "Accuracy = 18.3% (366/2000) (classification)\n",
      "gamma-value: 6.70018750350959e-05 ,Accuracy: (18.3, 11.3, 0.13506511772361537)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 8.185467307069021e-05 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0001 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.00012216773489967905 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0001492495545051829 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.00018233480008684422 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.00022275429519995563 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0002721338768375309 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.00033245979322709383 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.00040615859883769796 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0004961947603002898 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0006061898993497572 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0007405684692262443 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0009047357242349293 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0011052951411260222 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0013503140378698722 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0016496480740980208 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0020153376859417312 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0024620924014946257 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.0030078825180430958 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.003674661940736688 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n",
      "Accuracy = 10.85% (217/2000) (classification)\n",
      "gamma-value: 0.004489251258218608 ,Accuracy: (10.85, 21.632, nan)\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-75f5d394d9fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mparam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-s 0 -t 2 -g '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msvm_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gamma-value:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\",Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\libsvm\\svmutil.py\u001b[0m in \u001b[0;36msvm_predict\u001b[1;34m(y, x, m, options)\u001b[0m\n\u001b[0;32m    236\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                                 \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_svm_nodearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misKernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPRECOMPUTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m                         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_predict_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m                         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnr_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c_=np.logspace(-15,10,13)\n",
    "g_=np.logspace(-8,-2,70)\n",
    "for i in range(len(g_)):\n",
    "    problem=svm_problem(y_train,X_train)\n",
    "    param='-s 0 -t 2 -g '+str(g_[i])\n",
    "    m = svm_train(y_train,X_train,param)\n",
    "    predicted_labels,a,b= svm_predict(y_test,t,m) \n",
    "    print(\"gamma-value:\",g_[i],\",Accuracy:\",a)\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.9% (1958/2000) (classification)\n"
     ]
    }
   ],
   "source": [
    "problem=svm_problem(y_train,X_train)\n",
    "param='-s 0 -t 2 -g '+str(1e-06)\n",
    "m = svm_train(y_train,X_train,param)\n",
    "predicted_labels,a,b= svm_predict(y_test,t,m) \n",
    "    #print(\"gamma-value:\",c_[i],\",Accuracy:\",a)\n",
    "    #print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.)(b) Performing SVM classification using RBF Kernel and also Tuning the hyperparameter c (cost or penatly on classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 47.7% (954/2000) (classification)\n",
      "c-value: 0.01 ,Accuracy: (47.699999999999996, 7.5395, 0.3789641820652754)\n",
      "-----------------------------------------\n",
      "Accuracy = 73.55% (1471/2000) (classification)\n",
      "c-value: 0.013894954943731374 ,Accuracy: (73.55000000000001, 4.569, 0.5719939932844847)\n",
      "-----------------------------------------\n",
      "Accuracy = 85.7% (1714/2000) (classification)\n",
      "c-value: 0.019306977288832496 ,Accuracy: (85.7, 2.813, 0.7089795423941634)\n",
      "-----------------------------------------\n",
      "Accuracy = 88.8% (1776/2000) (classification)\n",
      "c-value: 0.02682695795279726 ,Accuracy: (88.8, 2.2585, 0.7576288759902196)\n",
      "-----------------------------------------\n",
      "Accuracy = 91.15% (1823/2000) (classification)\n",
      "c-value: 0.0372759372031494 ,Accuracy: (91.14999999999999, 1.8675, 0.7960369363114971)\n",
      "-----------------------------------------\n",
      "Accuracy = 92.55% (1851/2000) (classification)\n",
      "c-value: 0.0517947467923121 ,Accuracy: (92.55, 1.467, 0.8367544184441233)\n",
      "-----------------------------------------\n",
      "Accuracy = 93.75% (1875/2000) (classification)\n",
      "c-value: 0.07196856730011521 ,Accuracy: (93.75, 1.1675, 0.8679678539926621)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.35% (1887/2000) (classification)\n",
      "c-value: 0.1 ,Accuracy: (94.35, 1.0705, 0.8785818335613423)\n",
      "-----------------------------------------\n",
      "Accuracy = 94.9% (1898/2000) (classification)\n",
      "c-value: 0.13894954943731375 ,Accuracy: (94.89999999999999, 0.8675, 0.9008965968260022)\n",
      "-----------------------------------------\n",
      "Accuracy = 95.9% (1918/2000) (classification)\n",
      "c-value: 0.19306977288832497 ,Accuracy: (95.89999999999999, 0.649, 0.9252769933142597)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.55% (1931/2000) (classification)\n",
      "c-value: 0.2682695795279725 ,Accuracy: (96.55, 0.541, 0.9375074275060431)\n",
      "-----------------------------------------\n",
      "Accuracy = 96.8% (1936/2000) (classification)\n",
      "c-value: 0.372759372031494 ,Accuracy: (96.8, 0.496, 0.9427653845596059)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.2% (1944/2000) (classification)\n",
      "c-value: 0.517947467923121 ,Accuracy: (97.2, 0.472, 0.9454978046004716)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.45% (1949/2000) (classification)\n",
      "c-value: 0.7196856730011517 ,Accuracy: (97.45, 0.458, 0.9471363192340609)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 1.0 ,Accuracy: (97.89999999999999, 0.3355, 0.9611933630067309)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.95% (1959/2000) (classification)\n",
      "c-value: 1.3894954943731375 ,Accuracy: (97.95, 0.3095, 0.96414622976418)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.95% (1959/2000) (classification)\n",
      "c-value: 1.9306977288832496 ,Accuracy: (97.95, 0.299, 0.9653040966470079)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.85% (1957/2000) (classification)\n",
      "c-value: 2.6826957952797246 ,Accuracy: (97.85000000000001, 0.325, 0.9623010914332978)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.85% (1957/2000) (classification)\n",
      "c-value: 3.727593720314938 ,Accuracy: (97.85000000000001, 0.325, 0.9623010914332978)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 5.179474679231207 ,Accuracy: (97.89999999999999, 0.326, 0.9622063113882194)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 7.196856730011514 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 10.0 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 13.894954943731374 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 19.306977288832496 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 26.826957952797247 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 37.27593720314938 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 51.794746792312075 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 71.96856730011514 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 100.0 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 138.9495494373136 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 193.06977288832496 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 268.26957952797216 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 372.7593720314938 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 517.9474679231213 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 719.6856730011514 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 1000.0 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 1389.4954943731361 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 1930.6977288832495 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 2682.695795279722 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 3727.593720314938 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 5179.474679231202 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 7196.856730011514 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 10000.0 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 13894.95494373136 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 19306.977288832495 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 26826.95795279722 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 37275.93720314938 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 51794.74679231202 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 71968.56730011514 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n",
      "Accuracy = 97.9% (1958/2000) (classification)\n",
      "c-value: 100000.0 ,Accuracy: (97.89999999999999, 0.356, 0.9587808968450874)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "c_=np.logspace(-2,5,50)\n",
    "g_=np.logspace(-9,3,13)\n",
    "for i in range(len(c_)):\n",
    "    problem=svm_problem(y_train,X_train)\n",
    "    param='-s 0 -t 2 -g '+str(1e-06)+' -c '+str(c_[i])\n",
    "    m = svm_train(y_train,X_train,param)\n",
    "    predicted_labels,a,b= svm_predict(y_test,t,m) \n",
    "    print(\"c-value:\",c_[i],\",Accuracy:\",a)\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.95% (1959/2000) (classification)\n"
     ]
    }
   ],
   "source": [
    "problem=svm_problem(y_train,X_train)\n",
    "param='-s 0 -t 2 -g '+str(1e-06)+' -c '+str(1.3894954943731375)\n",
    "m = svm_train(y_train,X_train,param)\n",
    "predicted_labels,a,b= svm_predict(y_test,t,m) \n",
    "    #print(\"gamma-value:\",c_[i],\",Accuracy:\",a)\n",
    "    #print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label=(df['Label']).values.tolist()\n",
    "features1=[]\n",
    "dict={}\n",
    "feature_data1=[]\n",
    "t1=[]\n",
    "x1=[]\n",
    "for i in range(1,26):\n",
    "    s=str('f')+str(i)\n",
    "    features1.append((df1[s]).values.tolist())\n",
    "def libsvm_format(features1):\n",
    "    for i in range(0,len(features1[0])):\n",
    "        dict={}\n",
    "        for j in range(0,len(features1)):\n",
    "            dict[j+1]=features1[j][i]\n",
    "        feature_data1.append(dict)\n",
    "    return feature_data1\n",
    "x1=np.transpose(features1[0:25])      \n",
    "#y1=label\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "len(features1[0]),len(t1),len(x1)\n",
    "t1=libsvm_format(np.transpose(x1))\n",
    "len(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 9.8% (196/2000) (classification)\n"
     ]
    }
   ],
   "source": [
    "c_=np.logspace(-15,10,16)\n",
    "g_=np.logspace(-9,3,13)\n",
    "\n",
    "problem=svm_problem(y,x)\n",
    "#param='-s 0 -t 2 -g '+str(1e-06)+' -c '+str(1.9306977288832496)\n",
    "param='-s 0 -t 2 -g '+str(1e-06)+' -c '+str(1.3894954943731375)\n",
    "m = svm_train(y,x,param);\n",
    "predicted_labels,a,b= svm_predict([],t1,m);\n",
    "output=predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out=pd.DataFrame({'id':str(0),'class':str(int(output[0]))},index=[0])\n",
    "for i in range(1,len(output)):\n",
    "    df_out=df_out.append({'id':str(i),'class':str(int(output[i]))},ignore_index=True)\n",
    "df_out.to_csv('submission4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id class\n",
       "0        0     3\n",
       "1        1     5\n",
       "2        2     2\n",
       "3        3     7\n",
       "4        4     6\n",
       "...    ...   ...\n",
       "1995  1995     8\n",
       "1996  1996     1\n",
       "1997  1997     7\n",
       "1998  1998     2\n",
       "1999  1999     5\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
